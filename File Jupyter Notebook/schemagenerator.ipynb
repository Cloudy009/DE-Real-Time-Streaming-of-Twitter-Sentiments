{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e260d227",
   "metadata": {
    "id": "adb570d5"
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.avro.functions import from_avro, to_avro\n",
    "import pandas as pd\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3c584fe",
   "metadata": {},
   "source": [
    "<span style=\"color: blue; font-size:20px; font-weight:bold \">Tạo Spark Session với cấu hình tương tác với Kafka</span> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "812a6732",
   "metadata": {
    "id": "7dbd4cd0"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ivy Default Cache set to: /root/.ivy2/cache\n",
      "The jars for the packages stored in: /root/.ivy2/jars\n",
      ":: loading settings :: url = jar:file:/usr/local/lib/python3.7/dist-packages/pyspark/jars/ivy-2.4.0.jar!/org/apache/ivy/core/settings/ivysettings.xml\n",
      "org.apache.spark#spark-sql-kafka-0-10_2.12 added as a dependency\n",
      "org.apache.spark#spark-avro_2.12 added as a dependency\n",
      "org.mongodb.spark#mongo-spark-connector_2.12 added as a dependency\n",
      ":: resolving dependencies :: org.apache.spark#spark-submit-parent-11d88f23-e7fb-4ec4-89f8-d4049447632b;1.0\n",
      "\tconfs: [default]\n",
      "\tfound org.apache.spark#spark-sql-kafka-0-10_2.12;3.0.0 in central\n",
      "\tfound org.apache.spark#spark-token-provider-kafka-0-10_2.12;3.0.0 in central\n",
      "\tfound org.apache.kafka#kafka-clients;2.4.1 in central\n",
      "\tfound com.github.luben#zstd-jni;1.4.4-3 in central\n",
      "\tfound org.lz4#lz4-java;1.7.1 in central\n",
      "\tfound org.xerial.snappy#snappy-java;1.1.7.5 in central\n",
      "\tfound org.slf4j#slf4j-api;1.7.30 in central\n",
      "\tfound org.spark-project.spark#unused;1.0.0 in central\n",
      "\tfound org.apache.commons#commons-pool2;2.6.2 in central\n",
      "\tfound org.apache.spark#spark-avro_2.12;3.0.0 in central\n",
      "\tfound org.mongodb.spark#mongo-spark-connector_2.12;3.0.0 in central\n",
      "\tfound org.mongodb#mongodb-driver-sync;4.0.5 in central\n",
      "\tfound org.mongodb#bson;4.0.5 in central\n",
      "\tfound org.mongodb#mongodb-driver-core;4.0.5 in central\n",
      ":: resolution report :: resolve 660ms :: artifacts dl 14ms\n",
      "\t:: modules in use:\n",
      "\tcom.github.luben#zstd-jni;1.4.4-3 from central in [default]\n",
      "\torg.apache.commons#commons-pool2;2.6.2 from central in [default]\n",
      "\torg.apache.kafka#kafka-clients;2.4.1 from central in [default]\n",
      "\torg.apache.spark#spark-avro_2.12;3.0.0 from central in [default]\n",
      "\torg.apache.spark#spark-sql-kafka-0-10_2.12;3.0.0 from central in [default]\n",
      "\torg.apache.spark#spark-token-provider-kafka-0-10_2.12;3.0.0 from central in [default]\n",
      "\torg.lz4#lz4-java;1.7.1 from central in [default]\n",
      "\torg.mongodb#bson;4.0.5 from central in [default]\n",
      "\torg.mongodb#mongodb-driver-core;4.0.5 from central in [default]\n",
      "\torg.mongodb#mongodb-driver-sync;4.0.5 from central in [default]\n",
      "\torg.mongodb.spark#mongo-spark-connector_2.12;3.0.0 from central in [default]\n",
      "\torg.slf4j#slf4j-api;1.7.30 from central in [default]\n",
      "\torg.spark-project.spark#unused;1.0.0 from central in [default]\n",
      "\torg.xerial.snappy#snappy-java;1.1.7.5 from central in [default]\n",
      "\t---------------------------------------------------------------------\n",
      "\t|                  |            modules            ||   artifacts   |\n",
      "\t|       conf       | number| search|dwnlded|evicted|| number|dwnlded|\n",
      "\t---------------------------------------------------------------------\n",
      "\t|      default     |   14  |   0   |   0   |   0   ||   14  |   0   |\n",
      "\t---------------------------------------------------------------------\n",
      ":: retrieving :: org.apache.spark#spark-submit-parent-11d88f23-e7fb-4ec4-89f8-d4049447632b\n",
      "\tconfs: [default]\n",
      "\t0 artifacts copied, 14 already retrieved (0kB/14ms)\n",
      "24/11/21 02:24:59 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/11/21 02:25:01 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n"
     ]
    }
   ],
   "source": [
    "# spark.sparkContext.stop()\n",
    "\n",
    "#Spark Session creation configured to interact with Kafka\n",
    "spark = SparkSession.builder.appName(\"pyspark-notebook\").\\\n",
    "config(\"spark.jars.packages\",\"org.apache.spark:spark-sql-kafka-0-10_2.12:3.0.0,org.apache.spark:spark-avro_2.12:3.0.0,org.mongodb.spark:mongo-spark-connector_2.12:3.0.0\").\\\n",
    "getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5d27db68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.0.0\n"
     ]
    }
   ],
   "source": [
    "print(spark.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ae421bb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# spark = SparkSession.builder.getOrCreate()\n",
    "# spark.sparkContext.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33e7e377",
   "metadata": {},
   "source": [
    "<span style=\"color: blue; font-size:20px; font-weight:bold \">Đọc dữ liệu từ Kafka</span> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a1296f91",
   "metadata": {
    "id": "67bc7b14"
   },
   "outputs": [],
   "source": [
    "#Read data from Kafka\n",
    "data = spark\\\n",
    "  .readStream\\\n",
    "  .format(\"kafka\")\\\n",
    "  .option(\"kafka.bootstrap.servers\", \"intent-kafka-1:9092\")\\\n",
    "  .option(\"subscribe\", \"tweets\")\\\n",
    "  .option(\"startingOffsets\", \"earliest\")\\\n",
    "  .load()\\\n",
    "  .selectExpr(\"CAST(key AS STRING)\", \"CAST(value AS STRING)\")\\\n",
    "  .select(\"value\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0d0f327",
   "metadata": {},
   "source": [
    "<span style=\"color: blue; font-size:20px; font-weight:bold \">Ghi dữ liệu streaming vào file text:</span> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "90c52baa",
   "metadata": {
    "id": "efbd1206",
    "outputId": "b547127a-ac16-4ab8-ba86-6a0fce9eed0a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyspark.sql.streaming.StreamingQuery at 0x7fa9c015e2e8>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#write streaming data as a text file\n",
    "data.\\\n",
    "writeStream.\\\n",
    "format(\"text\").\\\n",
    "option(\"checkpointLocation\", \"checkpoint/schema\").\\\n",
    "option(\"format\", \"text\").\\\n",
    "option(\"path\", \"schema/in\").\\\n",
    "outputMode(\"append\").\\\n",
    "start()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b6d5651",
   "metadata": {},
   "source": [
    "<span style=\"color: blue; font-size:20px; font-weight:bold \">Trích xuất schema bằng cách đọc file đã ghi ở trên</span> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f65a59de",
   "metadata": {
    "id": "e3e0391f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/11/21 02:25:11 WARN package: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n"
     ]
    }
   ],
   "source": [
    "#extract schema by reading the file written above\n",
    "smallBatchSchema = spark.read.json(\"schema/in/*.txt\").schema"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40c36e2c",
   "metadata": {},
   "source": [
    "<span style=\"color: blue; font-size:20px; font-weight:bold \">Ghi schema vào file JSON</span> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "237c216c",
   "metadata": {
    "id": "b67a64c3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Schema đã được ghi vào schema/out/tweet_schema.json\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "# Đường dẫn tới thư mục và file\n",
    "dir_path = \"schema/out\"\n",
    "file_path = os.path.join(dir_path, \"tweet_schema.json\")\n",
    "\n",
    "# Tạo thư mục nếu chưa tồn tại\n",
    "if not os.path.exists(dir_path):\n",
    "    os.makedirs(dir_path)\n",
    "\n",
    "# Ghi schema vào file JSON\n",
    "with open(file_path, \"w\") as f:\n",
    "    json.dump(smallBatchSchema.jsonValue(), f)\n",
    "\n",
    "print(f\"Schema đã được ghi vào {file_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cf3cb70",
   "metadata": {},
   "source": [
    "<span style=\"color: red; font-size:30px; font-weight:bold \">Mục đích cuối cùng của file</span> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29f38d33",
   "metadata": {},
   "source": [
    "### Mục đích của file schemagenerator này là đọc dữ liệu streaming từ Kafka, ghi dữ liệu vào file text, trích xuất schema của dữ liệu đó và ghi schema vào file JSON. Việc này giúp lưu trữ schema của dữ liệu để có thể sử dụng lại hoặc phân tích sau này."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31853344",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "schemagenerator.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
